{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f108d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install praw\n",
    "# %pip install psaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3959791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import praw \n",
    "from psaw import PushshiftAPI \n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60749e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/scraping-reddit-data-1c0af3040768\n",
    "# https://praw.readthedocs.io/en/latest/ \n",
    "# https://pypi.org/project/psaw/\n",
    "# Retrieve reddit client with api key login and a follow up of data retrieval \n",
    "# to use PSAW\n",
    "api = PushshiftAPI()\n",
    "reddit = praw.Reddit(client_id='jt4hWsKS8poo7txQtBXSAw',\n",
    "                     client_secret='CRteJYmAtXXSZNAPRqVcdMHQsAOlqQ',\n",
    "                     user_agent='Quantliop_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346f4c1d",
   "metadata": {},
   "source": [
    "# NIKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347eef21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "start_epoch=int(dt.datetime(2022, 8, 1).timestamp())\n",
    "after_epoch = int(dt.datetime(2022, 9, 30).timestamp())\n",
    "Nike_sub = api.search_submissions(after=start_epoch,\n",
    "                            before= after_epoch, \n",
    "                            subreddit='Nike',\n",
    "                            filter=['url', 'title', 'subreddit','id','score','num_comments', 'created_utc', 'score'])\n",
    "sub_dict = {\"Title\": [], \"Subreddit\": [],\n",
    "              \"ID\": [], \"Score\": [],\n",
    "              \"Total Comments\": [], \"Post URL\": [],\n",
    "              \"created_utc\": [], \"score\": []\n",
    "              }   \n",
    "for post in Nike_sub:\n",
    "    # Title of each post\n",
    "    sub_dict[\"Title\"].append(post.title)  \n",
    "    \n",
    "    # subreddit\n",
    "    sub_dict[\"Subreddit\"].append(post.subreddit)\n",
    "     \n",
    "    # Unique ID of each post\n",
    "    sub_dict[\"ID\"].append(post.id)\n",
    "     \n",
    "    # The score of a post\n",
    "    sub_dict[\"Score\"].append(post.score)\n",
    "     \n",
    "    # Total number of comments inside the post\n",
    "    sub_dict[\"Total Comments\"].append(post.num_comments)\n",
    "     \n",
    "    # URL of each post\n",
    "    sub_dict[\"Post URL\"].append(post.url) \n",
    "\n",
    "    # Total number of comments inside the post\n",
    "    sub_dict[\"created_utc\"].append(post.created_utc)\n",
    "     \n",
    "    # URL of each post\n",
    "    sub_dict[\"score\"].append(post.score) \n",
    "\n",
    "\n",
    "top_posts = pd.DataFrame(sub_dict) \n",
    "top_posts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a19b48",
   "metadata": {},
   "source": [
    "# Adidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc999d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Adidas = api.search_submissions(after=start_epoch, \n",
    "                                before= after_epoch,\n",
    "                            subreddit='Adidas',\n",
    "                            filter=['url', 'title', 'subreddit','id','score','num_comments'])  \n",
    "for i in Adidas:\n",
    "    # Title of each post\n",
    "    sub_dict[\"Title\"].append(i.title)  \n",
    "    \n",
    "    # subreddit\n",
    "    sub_dict[\"Subreddit\"].append(i.subreddit)\n",
    "     \n",
    "    # Unique ID of each post\n",
    "    sub_dict[\"ID\"].append(i.id)\n",
    "     \n",
    "    # The score of a post\n",
    "    sub_dict[\"Score\"].append(i.score)\n",
    "     \n",
    "    # Total number of comments inside the post\n",
    "    sub_dict[\"Total Comments\"].append(i.num_comments)\n",
    "     \n",
    "    # URL of each post\n",
    "    sub_dict[\"Post URL\"].append(i.url) \n",
    "\n",
    "\n",
    "top_posts = pd.DataFrame(sub_dict) \n",
    "len(top_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303cc5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Converse = api.search_submissions(after=start_epoch, \n",
    "                                  before= after_epoch,\n",
    "                            subreddit='Converse',\n",
    "                            filter=['url', 'title', 'subreddit','id','score','num_comments'])  \n",
    "for i in Converse:\n",
    "    # Title of each post\n",
    "    sub_dict[\"Title\"].append(i.title)  \n",
    "    \n",
    "    # subreddit\n",
    "    sub_dict[\"Subreddit\"].append(i.subreddit)\n",
    "     \n",
    "    # Unique ID of each post\n",
    "    sub_dict[\"ID\"].append(i.id)\n",
    "     \n",
    "    # The score of a post\n",
    "    sub_dict[\"Score\"].append(i.score)\n",
    "     \n",
    "    # Total number of comments inside the post\n",
    "    sub_dict[\"Total Comments\"].append(i.num_comments)\n",
    "     \n",
    "    # URL of each post\n",
    "    sub_dict[\"Post URL\"].append(i.url) \n",
    "\n",
    "\n",
    "top_posts = pd.DataFrame(sub_dict) \n",
    "len(top_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4bf9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Reebok = api.search_submissions(after=start_epoch, \n",
    "                                before= after_epoch,\n",
    "                            subreddit='Reebok',\n",
    "                            filter=['url', 'title', 'subreddit','id','score','num_comments'])  \n",
    "for i in Reebok:\n",
    "    # Title of each post\n",
    "    sub_dict[\"Title\"].append(i.title)  \n",
    "    \n",
    "    # subreddit\n",
    "    sub_dict[\"Subreddit\"].append(i.subreddit)\n",
    "     \n",
    "    # Unique ID of each post\n",
    "    sub_dict[\"ID\"].append(i.id)\n",
    "     \n",
    "    # The score of a post\n",
    "    sub_dict[\"Score\"].append(i.score)\n",
    "     \n",
    "    # Total number of comments inside the post\n",
    "    sub_dict[\"Total Comments\"].append(i.num_comments)\n",
    "     \n",
    "    # URL of each post\n",
    "    sub_dict[\"Post URL\"].append(i.url) \n",
    "\n",
    "\n",
    "top_posts = pd.DataFrame(sub_dict) \n",
    "len(top_posts)\n",
    "top_posts.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01279a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_posts.to_csv(\"reddit_api_export.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850541eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nick_num = 0  \n",
    "adidas_num = 0 \n",
    "converse_num = 0 \n",
    "Reebok_num = 0\n",
    "for i in top_posts.loc[:,\"Subreddit\"]: \n",
    "    if i == \"Nike\": \n",
    "        nick_num += 1  \n",
    "    elif i == \"adidas\": \n",
    "        adidas_num += 1 \n",
    "    elif i == \"Converse\": \n",
    "        converse_num += 1 \n",
    "    else: \n",
    "        Reebok_num += 1\n",
    "n_of_reddit = [nick_num,adidas_num,converse_num,Reebok_num] \n",
    "n_of_reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b9fb89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdfc670",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "a36ec43899a0caf4b8e96327d984f7682f5de923829754118f66a7729dbb8889"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
